"""Inferencia por enumeración en redes bayesianas con trazado detallado.

Este módulo implementa el algoritmo de enumeración para inferencia exacta en
redes bayesianas discretas, con un registro detallado del proceso de cómputo.
"""
import itertools
from collections import defaultdict
from pathlib import Path
import pandas as pd
import networkx as nx


class RastreadorInferencia:
    """Rastrea y registra los pasos de cómputo de la inferencia."""
    def __init__(self, archivo_log=None):
        self.pasos = []
        self.archivo_log = Path(archivo_log) if archivo_log else None
        if self.archivo_log:
            # Iniciar log nuevo
            self.archivo_log.write_text('')
    
    def agregar_paso(self, msg):
        """Agrega un paso de cómputo y opcionalmente lo escribe al archivo."""
        print(msg)  # Siempre imprimir a consola
        self.pasos.append(msg)
        if self.archivo_log:
            with open(self.archivo_log, 'a', encoding='utf-8') as f:
                f.write(msg + '\n')


def enumerar_todo(variables, evidencia, G, vars_red, rastreador):
    """Retorna la distribución sobre la variable de consulta por enumeración.
    
    Args:
        variables: List[str], variables a enumerar (en orden topológico)
        evidencia: dict, variable -> asignación de valores
        G: networkx.DiGraph con CPTs almacenadas en atributos de nodos
        vars_red: dict que mapea cada variable a sus valores posibles
        rastreador: RastreadorInferencia para registrar pasos
    
    Returns:
        float: probabilidad de la evidencia
    """
    if not variables:
        return 1.0
    
    Y, rest = variables[0], variables[1:]
    tracer.add_step(f"\nEnumerating over {Y}")
    tracer.add_step(f"  Current evidence: {evidence}")
    
    if Y in evidence:
        # Variable already has value in evidence
        py = probability(Y, evidence, G)
        tracer.add_step(f"  {Y} in evidence, P({Y}={evidence[Y]}|parents)={py:.4f}")
        result = py * enumerate_all(rest, evidence, G, bn_vars, tracer)
        tracer.add_step(f"  Returning {result:.4f}")
        return result
    
    # Sum over possible values of Y
    total = 0
    tracer.add_step(f"  Summing over values of {Y}: {bn_vars[Y]}")
    for y in bn_vars[Y]:
        evidence[Y] = y
        py = probability(Y, evidence, G)
        tracer.add_step(f"    P({Y}={y}|parents)={py:.4f}")
        sub = py * enumerate_all(rest, evidence, G, bn_vars, tracer)
        tracer.add_step(f"    Term for {Y}={y}: {sub:.4f}")
        total += sub
    evidence.pop(Y)  # Remove from evidence before returning
    tracer.add_step(f"  Sum for {Y}: {total:.4f}")
    return total


def probability(var, evidence, G):
    """Return probability of var=val given parents values in evidence.
    
    The CPT for each node should be stored in G.nodes[var]['cpt'] as a pandas DataFrame
    with columns for parent values (if any) and 'value', 'prob'.
    """
    cpt = G.nodes[var]['cpt']
    # Get parents and their values from evidence
    parents = list(G.predecessors(var))
    if not parents:
        # No parents - just look up probability
        return float(cpt[cpt['value'] == evidence[var]]['prob'].iloc[0])
    
    # Match parent values in CPT
    query = {p: evidence[p] for p in parents}
    query['value'] = evidence[var]
    # Use pandas boolean indexing to find matching row
    matches = cpt
    for col, val in query.items():
        matches = matches[matches[col] == val]
    return float(matches['prob'].iloc[0])


def enumeration_ask(X, evidence, G, bn_vars=None, log_file=None):
    """Return distribution over X by enumeration given evidence.
    
    Args:
        X: str, query variable
        evidence: dict mapping variables to values
        G: networkx.DiGraph with CPTs stored in node attributes
        bn_vars: optional dict mapping variables to their possible values
               (defaults to {True, False} for all variables)
        log_file: optional path to write computation trace
    
    Returns:
        Distribution over X as dict mapping values to probabilities
    """
    if bn_vars is None:
        # Default to binary variables
        bn_vars = {var: {True, False} for var in G.nodes}
    
    tracer = InferenceTracer(log_file)
    tracer.add_step(f"\nComputing P({X}|{evidence})")
    
    # Get all variables in topological order (ensures correct enumeration order)
    variables = list(nx.topological_sort(G))
    tracer.add_step(f"Variables in topological order: {variables}")
    
    # Compute distribution by normalizing across query variable values
    Q = defaultdict(float)
    for x in bn_vars[X]:
        evidence[X] = x
        tracer.add_step(f"\nComputing P({X}={x}, e)")
        Q[x] = enumerate_all(variables, evidence, G, bn_vars, tracer)
        tracer.add_step(f"P({X}={x}, e) = {Q[x]:.4f}")
    evidence.pop(X)
    
    # Normalize
    total = sum(Q.values())
    for x in Q:
        Q[x] /= total
        tracer.add_step(f"P({X}={x}|e) = {Q[x]:.4f}")
    
    return dict(Q)  # Convert defaultdict to regular dict


if __name__ == '__main__':
    # Small test/demo
    from bayesnet import build_bayesnet
    
    edges = Path(__file__).resolve().parents[1] / 'data' / 'edges.csv'
    cpt_folder = edges.parent
    G = build_bayesnet(edges, cpt_folder)
    
    # P(Rain | GrassWet=true)
    evidence = {'GrassWet': True}
    dist = enumeration_ask('Rain', evidence, G, log_file='trace.txt')
    print(f"\nP(Rain|GrassWet=true) = {dist}")